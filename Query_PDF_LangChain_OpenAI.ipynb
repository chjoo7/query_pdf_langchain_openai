{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1746b2",
   "metadata": {},
   "source": [
    "###  Question to PDF using LangChain and OpenAI LLM ###\n",
    "- Ask a question using Korean sentence target to large PDF files via LangChain and OpenAI API.\n",
    "- Split documents using LangChain splitter or fixed chunks and store into Dataframe\n",
    "- Query embedding compare cosine similarity with embedding data in Dataframe and return by similarity ranking TopN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e02191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: openai in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.27.4)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8af1451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.0.141)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.8/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (0.1.11)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (8.2.1)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (19.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.8/dist-packages (from gptcache>=0.1.7->langchain) (5.2.0)\n",
      "Requirement already satisfied: openai in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from gptcache>=0.1.7->langchain) (0.27.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai->gptcache>=0.1.7->langchain) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15eb86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (8.10.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython) (2.14.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython) (0.6.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /usr/local/lib/python3.8/dist-packages (from ipython) (3.0.36)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.8/dist-packages (from ipython) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython) (0.7.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython) (2.2.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython) (0.7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1ae286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111b9049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tiktoken in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied, skipping upgrade: regex>=2022.1.18 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->tiktoken) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65c775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cb4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.3.21)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (0.95.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (1.10.7)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.8/dist-packages (from chromadb) (1.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (2.2.2)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (0.5.20)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.8/dist-packages (from chromadb) (2.28.2)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from chromadb) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->chromadb) (2020.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.12.1+cu113)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
      "Requirement already satisfied: nltk in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.98)\n",
      "Requirement already satisfied: torchvision in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.1+cu113)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: zstandard in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.8/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.14)\n",
      "Requirement already satisfied: lz4 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->chromadb) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: h11>=0.8 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13; extra == \"standard\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4; extra == \"standard\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0; sys_platform != \"win32\" and (sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\") and extra == \"standard\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: pyyaml>=5.1; extra == \"standard\" in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: httptools>=0.5.0; extra == \"standard\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: watchfiles>=0.13; extra == \"standard\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (3.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ced6d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.5.12)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from unstructured) (1.4.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from unstructured) (2.28.2)\n",
      "Requirement already satisfied: openpyxl in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: pypandoc in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.8/dist-packages (from unstructured) (2022.12.7)\n",
      "Requirement already satisfied: argilla in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (1.6.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: msg-parser in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from unstructured) (9.4.0)\n",
      "Requirement already satisfied: python-pptx in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.8/dist-packages (from unstructured) (3.3.7)\n",
      "Requirement already satisfied: nltk in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: python-magic in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: python-docx in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pandas->unstructured) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->unstructured) (2020.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured) (1.26.14)\n",
      "Requirement already satisfied: et-xmlfile in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: backoff in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (2.2.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (1.14.1)\n",
      "Requirement already satisfied: pydantic>=1.7.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (1.10.7)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (1.2.13)\n",
      "Requirement already satisfied: monotonic in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (1.6)\n",
      "Requirement already satisfied: rich<=13.0.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (13.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.8/dist-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from argilla->unstructured) (23.0)\n",
      "Requirement already satisfied: olefile>=0.46 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from python-pptx->unstructured) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown->unstructured) (6.0.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from nltk->unstructured) (2023.3.23)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->unstructured) (8.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown->unstructured) (3.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de774ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[local-inference] in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (0.5.12)\n",
      "Requirement already satisfied: python-docx in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (0.8.11)\n",
      "Requirement already satisfied: msg-parser in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (1.2.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (9.4.0)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (3.3.7)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (2022.12.7)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (4.9.2)\n",
      "Requirement already satisfied: argilla in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (1.6.0)\n",
      "Requirement already satisfied: nltk in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (3.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (1.4.4)\n",
      "Requirement already satisfied: python-magic in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (0.4.27)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from unstructured[local-inference]) (2.28.2)\n",
      "Requirement already satisfied: openpyxl in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (3.1.2)\n",
      "Requirement already satisfied: pypandoc in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (1.11)\n",
      "Requirement already satisfied: python-pptx in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (0.6.21)\n",
      "Requirement already satisfied: unstructured-inference==0.3.2; extra == \"local-inference\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured[local-inference]) (0.3.2)\n",
      "Requirement already satisfied: olefile>=0.46 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from msg-parser->unstructured[local-inference]) (0.46)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown->unstructured[local-inference]) (6.0.0)\n",
      "Requirement already satisfied: monotonic in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (1.6)\n",
      "Requirement already satisfied: pydantic>=1.7.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (1.10.7)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (0.23.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.8/dist-packages (from argilla->unstructured[local-inference]) (4.65.0)\n",
      "Requirement already satisfied: backoff in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (2.2.1)\n",
      "Requirement already satisfied: rich<=13.0.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (13.0.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (1.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from argilla->unstructured[local-inference]) (23.0)\n",
      "Requirement already satisfied: numpy<1.24.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (1.23.5)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from argilla->unstructured[local-inference]) (1.2.13)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from nltk->unstructured[local-inference]) (2023.3.23)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->unstructured[local-inference]) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->unstructured[local-inference]) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->unstructured[local-inference]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->unstructured[local-inference]) (2020.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured[local-inference]) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured[local-inference]) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->unstructured[local-inference]) (3.4)\n",
      "Requirement already satisfied: et-xmlfile in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from openpyxl->unstructured[local-inference]) (1.1.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from python-pptx->unstructured[local-inference]) (3.1.0)\n",
      "Requirement already satisfied: uvicorn in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.21.1)\n",
      "Requirement already satisfied: onnxruntime in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.14.1)\n",
      "Requirement already satisfied: transformers in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (4.28.1)\n",
      "Requirement already satisfied: python-multipart in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.0.6)\n",
      "Requirement already satisfied: huggingface-hub in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.13.4)\n",
      "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.3.4)\n",
      "Requirement already satisfied: fastapi in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.95.1)\n",
      "Requirement already satisfied: opencv-python==4.6.0.66 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (4.6.0.66)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown->unstructured[local-inference]) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pydantic>=1.7.1->argilla->unstructured[local-inference]) (4.5.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (0.16.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.3.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (2.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured[local-inference]) (1.16.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from uvicorn->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.14.0)\n",
      "Requirement already satisfied: flatbuffers in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (23.3.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.11.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (15.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (6.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from transformers->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (3.11.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from transformers->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.13.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iopath in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.1.9)\n",
      "Requirement already satisfied: pdf2image in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.16.3)\n",
      "Requirement already satisfied: pdfplumber in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.9.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.10.1)\n",
      "Requirement already satisfied: effdet; extra == \"layoutmodels\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.3.0)\n",
      "Requirement already satisfied: torch; extra == \"layoutmodels\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision; extra == \"layoutmodels\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.13.1+cu113)\n",
      "Requirement already satisfied: pytesseract; extra == \"tesseract\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.3.10)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from fastapi->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.26.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (3.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.2.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from coloredlogs->onnxruntime->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (10.0)\n",
      "Requirement already satisfied: portalocker in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (2.7.0)\n",
      "Requirement already satisfied: Wand>=0.6.10 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.6.11)\n",
      "Requirement already satisfied: pdfminer.six==20221105 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (20221105)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (2.3.0)\n",
      "Requirement already satisfied: timm>=0.4.12 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.6.13)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (2.0.6)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (40.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from omegaconf>=2.0->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (3.6.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.15.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet; extra == \"layoutmodels\"->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (1.4.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.3.2; extra == \"local-inference\"->unstructured[local-inference]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q unstructured[local-inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b57ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-ot09z5vg\n",
      "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-ot09z5vg\n",
      "Requirement already satisfied (use --upgrade to upgrade): detectron2==0.6 from git+https://github.com/facebookresearch/detectron2.git in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (9.4.0)\n",
      "Requirement already satisfied: black in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (23.3.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (2.2.1)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (1.3.2)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (3.6.3)\n",
      "Requirement already satisfied: omegaconf>=2.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (2.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (23.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (2.0.6)\n",
      "Requirement already satisfied: tabulate in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: tensorboard in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (2.2.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.8/dist-packages (from detectron2==0.6) (4.65.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (8.0.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (3.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from black->detectron2==0.6) (0.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0; python_version < \"3.10\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from black->detectron2==0.6) (4.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from black->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: numpy in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.12.0)\n",
      "Requirement already satisfied: portalocker in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.7.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.17.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (2.28.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.51.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (44.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core>=1.1->detectron2==0.6) (3.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0rc1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (6.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0rc2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\n",
      "Building wheels for collected packages: detectron2\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=6095013 sha256=42ebcaa7c5b34ed6773462ce34fc6870aa88d31bf067cf9554395a687850fd77\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3zab869x/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "Successfully built detectron2\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89dce12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: setuptools in /home/jovyan_venv/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages (from tika) (44.0.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tika) (2.28.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (3.0.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (1.26.14)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tika"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b06fb1",
   "metadata": {},
   "source": [
    "#### install dependencies ####\n",
    "- sudo apt-get update\n",
    "- sudo apt-get install poppler-utils\n",
    "- sudo apt install tesseract-ocr\n",
    "- sudo apt install libtesseract-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895bb53",
   "metadata": {},
   "source": [
    "#### Load Your Data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b905257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "raw = parser.from_file(\"./data/indsec.pdf\")\n",
    "content = raw['content']\n",
    "tex = content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64b2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = UnstructuredPDFLoader(\"./data/indsec.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d110f0f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (3784538299.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('Time elapsed (hh:mm:ss.ms) {}'.format(elapsed))\u001b[0m\n\u001b[0m                                                          \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime \n",
    "start_time = datetime.now()\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e05acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of data: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"type of data:\", type(tex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcf2184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659544"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d447935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.01227678571429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "659544 / 7168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc78cf0",
   "metadata": {},
   "source": [
    "# def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8f29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bece0199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532310\n"
     ]
    }
   ],
   "source": [
    "# Return the token number from string\n",
    "print(num_tokens_from_string(tex, 'cl100k_base'))   # 659544 string -> 532310 token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f7670",
   "metadata": {},
   "source": [
    "#### how many 7168 sized tokens do we have from texts token ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5863f17",
   "metadata": {},
   "source": [
    "Warning: although .decode() can be applied to single tokens, beware that it can be lossy for tokens that aren't on utf-8 boundaries.\n",
    "\n",
    "For single tokens, .decode_single_token_bytes() safely converts a single integer token to the bytes it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97db403",
   "metadata": {},
   "source": [
    "#### 6. Counting tokens for chat API calls\n",
    "- ChatGPT models like gpt-3.5-turbo and gpt-4 use tokens in the same way as older completions models, but because of their message-based formatting, it's more difficult to count how many tokens will be used by a conversation.\n",
    "\n",
    "- Below is an example function for counting tokens for messages passed to gpt-3.5-turbo-0301 or gpt-4-0314.\n",
    "\n",
    "- Note that the exact way that tokens are counted from messages may change from model to model. Consider the counts from the function below an estimate, not a timeless guarantee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3fb87",
   "metadata": {},
   "source": [
    "#### Importing libraries and selecting moidels ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915b35c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m  \u001b[38;5;66;03m# for converting embeddings saved as strings back to arrays\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m  \u001b[38;5;66;03m# for calling the OpenAI API\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# for storing text and embeddings data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m  \u001b[38;5;66;03m# for counting tokens\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "\n",
    "\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "EMBEDDING_CTX_LENGTH = 1000\n",
    "EMBEDDING_ENCODING = 'cl100k_base'\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0aae89",
   "metadata": {},
   "source": [
    "#### Chunking the input text ####\n",
    "- Divide the input text into chunks and embed each chunk individually to cope with 8191 length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ac4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def batched(iterable, n):\n",
    "    \"\"\"Batch data into tuples of length n. The last batch may be shorter.\"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    if str(it) == \"\\n\":\n",
    "        it = it.replace(\"\\n\", \" \")\n",
    "    while (batch := tuple(islice(it, n))):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dcb4a",
   "metadata": {},
   "source": [
    "#### Define a function that encodes a string into tokens and breaks it up into chunks ####\n",
    "- In this case, chunk consists of 8191 tokens which is a maximum token size of \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c16737f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_name = 'cl100k_base'\n",
    "def chunked_tokens(text, encoding_name, chunk_length):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks_iterator = batched(tokens, chunk_length)  # breaks tokens up into 2000 sized chunked_iterator tokens\n",
    "    yield from chunks_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86549441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb6c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20dcb4f",
   "metadata": {},
   "source": [
    "#### the average flag can be set to True to return the weighted average of the chunk embeddings, or False to simply return the unmodified list of chunk embeddings ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c967eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def len_safe_get_embedding(text, model=EMBEDDING_MODEL, max_tokens=EMBEDDING_CTX_LENGTH, encoding_name=EMBEDDING_ENCODING, average=True):\n",
    "    chunk_embeddings = []\n",
    "    chunk_lens = []\n",
    "    for chunk in chunked_tokens(text, encoding_name=encoding_name, chunk_length=max_tokens):\n",
    "        chunk_embeddings.append(get_embedding(chunk, model=model))\n",
    "        chunk_lens.append(len(chunk))\n",
    "\n",
    "    if average:\n",
    "        chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)\n",
    "        chunk_embeddings = chunk_embeddings / np.linalg.norm(chunk_embeddings)  # normalizes length to 1\n",
    "        chunk_embeddings = chunk_embeddings.tolist()\n",
    "    return chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e776fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting average=False gives us 75 embedding vectors, one for each of the chunks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "openai.api_key = os.get_env(OPENAI_API_KEY)\n",
    "#average_embedding_vector = len_safe_get_embedding(str(data), EMBEDDING_MODEL, EMBEDDING_CTX_LENGTH, EMBEDDING_ENCODING, average=True)\n",
    "chunks_embedding_vectors = len_safe_get_embedding(tex, average=False)\n",
    "\n",
    "#print(f\"Setting average=True gives us a single {len(average_embedding_vector)}-dimensional embedding vector for our long text.\")\n",
    "print(f\"Setting average=False gives us {len(chunks_embedding_vectors)} embedding vectors, one for each of the chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e160e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ce0e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'          \\n\\n(20230105)\\n\\n2023. 1. 5\\n\\n \\nKorea Law Service Center\\n\\n\\n\\n                                                            1                                                       \\n\\n       \\n \\n\\n1. \\n\\n2.  \\n\\n3.  \\n\\n4.   \\n\\n\\n\\n                                                            2                                                       \\n\\n\\n\\n \\n\\n            1 \\n \\n\\n1()              \\n\\n           \\n\\n   . < 2020. 5. 26.>\\n \\n\\n2()       . < 2020. 5. 26.>\\n\\n1.       \\n\\n            \\n\\n  .\\n\\n2.            \\n\\n    .\\n\\n3.   211   .\\n\\n4.       .\\n\\n5.         , \\n\\n   '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e54232",
   "metadata": {},
   "source": [
    "#### make 'id', 'embeddings' pair dataframe  ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c286269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39fec6a0aed4c0291573f2d7cb3c2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:00:47.358232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>          \\n\\n(20230105)\\n\\n2023...</td>\n",
       "      <td>[-0.00443989597260952, -0.0021884473972022533,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>   \\n\\n.\\n\\n1. 52    ...</td>\n",
       "      <td>[-0.0075674839317798615, -0.02437097765505314,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>     \\n\\n 2  ...</td>\n",
       "      <td>[-0.0010535597102716565, -0.0151447132229805, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>       \\n\\n...</td>\n",
       "      <td>[-0.0099439462646842, -0.025058744475245476, 0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> .\\n\\n 22    3  ...</td>\n",
       "      <td>[-0.004272471182048321, -0.018619533628225327,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0            \\n\\n(20230105)\\n\\n2023...   \n",
       "1     \\n\\n.\\n\\n1. 52    ...   \n",
       "2        \\n\\n 2  ...   \n",
       "3         \\n\\n...   \n",
       "4   .\\n\\n 22    3  ...   \n",
       "\n",
       "                                           embedding id  \n",
       "0  [-0.00443989597260952, -0.0021884473972022533,...  0  \n",
       "1  [-0.0075674839317798615, -0.02437097765505314,...  1  \n",
       "2  [-0.0010535597102716565, -0.0151447132229805, ...  2  \n",
       "3  [-0.0099439462646842, -0.025058744475245476, 0...  3  \n",
       "4  [-0.004272471182048321, -0.018619533628225327,...  4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "batch_size = EMBEDDING_CTX_LENGTH\n",
    "docs = []\n",
    "tiktoken_encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i in tqdm(range(0, len(tex), batch_size)): \n",
    "    # find end of batch\n",
    "    i_end = min(len(tex), i+batch_size)\n",
    "#    tokens - tiktoken_encoding.encode(file_content)\n",
    "#    tok = chunks_embedding_vectors[i]\n",
    "#    tok_len = len(tok)\n",
    "    meta_batch = tex[i:i_end]\n",
    "#    contents = data[0].page_content[i:i+batch_size]\n",
    "    docs.append(meta_batch)\n",
    "    \n",
    "df = pd.DataFrame(docs, columns=['text'])\n",
    "df['embedding'] = df.text.apply(lambda x:openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "\n",
    "df['id'] = [str(x) for x in range(len(df))]\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(elapsed))\n",
    "df.to_csv(\"embeddings_7168.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e0cec38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0011b27",
   "metadata": {},
   "source": [
    "####  ####\n",
    "    :\n",
    "\n",
    "-    test  embedding       \n",
    "-   OpenAI API      \n",
    "-    text        \n",
    "-   lists  :  \n",
    "    -   top N texts  \n",
    "    -   (0 ~ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ac79888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# search function\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11fa42e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n31  32      5    \\n\\n    .\\n\\n     26     \\n\\n     .\\n\\n \\n\\n            4   \\n \\n\\n37(    )    363  \\n\\n          .\\n\\n1.   \\n\\n2.   \\n\\n3.     \\n\\n4.         \\n\\n  \\n\\n  1   3  .\\n \\n\\n38(    )   372  \\n\\n    6 ,   ,  ,     7 .\\n\\n           \\n\\n     .        \\n\\n .\\n\\n        8 ,   \\n\\n      .\\n\\n             \\n\\n               \\n\\n.\\n \\n\\n39(  )    37    \\n\\n   7           \\n\\n\\n\\n                                                            16                                                       \\n\\n \\n\\n  .\\n\\n          \\n\\n   .\\n\\n           \\n\\n  .\\n \\n\\n40( )      9   \\n\\n  7    .\\n\\n            \\n\\n.\\n\\n          , \\n\\n   30   .\\n\\n        .\\n\\n           \\n\\n.\\n \\n\\n41(    )   411  \\n\\n        .\\n\\n1.  411          \\n\\n2.           \\n\\n3. 2          \\n\\n4.    411       \\n \\n\\n42( )   4211    \\n\\n    16       \\n\\n     15   2  .   \\n\\n , , ,       \\n\\n .\\n\\n1.    \\n\\n2.    \\n\\n3.  \\n\\n4.    ,    \\n\\n5.       \\n\\n  4212      \\n\\n  16         \\n\\n  15   2  .\\n\\n1.    \\n\\n\\n\\n                                                            17                                                       \\n\\n \\n\\n2.  \\n\\n3.       \\n\\n  4213       \\n\\n17    10     \\n\\n(         ,  \\n\\n         )   2\\n\\n .       62   \\n\\n       \\n\\n     .\\n\\n     423        \\n\\n         \\n\\n    .        \\n\\n    .\\n\\n  421       \\n\\n        11      (      \\n\\n  )    .\\n\\n     11      \\n\\n       18  \\n\\n   .         \\n\\n   .\\n \\n\\n43(   )  422  \\n\\n             \\n\\n .\\n\\n1.   \\n\\n2.     \\n\\n3.          \\n\\n  5,   7  \\n \\n\\n44(  )   42      \\n\\n   15       . , \\n\\n426        \\n\\n     .\\n\\n  1          \\n\\n         .\\n\\n          . ,\\n\\n        .\\n\\n\\n\\n                                                            18                                                       \\n\\n \\n\\n          \\n\\n145          19\\n\\n      .       \\n\\n          \\n\\n       .\\n\\n   4       \\n\\n  422       .\\n \\n\\n45(  )          \\n\\n.\\n\\n1. :          \\n\\n\\n\\n2.  :         \\n\\n\\n\\n3. :          \\n\\n           \\n\\n           20 \\n\\n     (    \\n\\n)       .\\n\\n          21 \\n\\n  ()       \\n\\n  (  \\n\\n .  )    .\\n\\n 3          \\n\\n,      .\\n\\n        \\n\\n      .\\n \\n\\n46()   4211  2    \\n\\n     ,  4213  \\n\\n   6   431       \\n\\n  .\\n\\n1.      \\n\\n2.  426    \\n\\n3.    \\n\\n  1          .\\n\\n\\n\\n                                                            19                                                       \\n\\n \\n\\n 444         \\n\\n        22   \\n\\n   1       \\n\\n  . ,    2 ( 1 3   \\n\\n)    .\\n\\n 3     444     \\n\\n  .\\n \\n\\n47(    )       11 \\n\\n    6  461      \\n\\n,         . ,    \\n\\n( 1 3   )   461 \\n\\n   .\\n\\n  1          .\\n \\n\\n48(   )   46  47      \\n\\n     5   23 \\n\\n    ,     \\n\\n     ,       \\n\\n 10   24       \\n\\n    .\\n\\n        433    ,\\n\\n           24\\n\\n           \\n\\n .\\n\\n 1  2          \\n\\n   .\\n \\n\\n49( )       \\n\\n           \\n\\n       .\\n\\n1.    \\n\\n2.    \\n\\n3. 43           \\n \\n\\n50(   )   44    \\n\\n    .\\n\\n\\n\\n                                          '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'        .\\n \\n\\n25( )      . <\\n\\n2020. 9. 8.>\\n\\n1.  29       \\n\\n2.  36      \\n\\n3.  125        \\n\\n4.  129 131        \\n\\n5.    ,         \\n\\n6.              \\n\\n\\n \\n\\n26(   )   194  \\n\\n        241  \\n\\n    .\\n\\n     192 .    \\n\\n175    1  194    1, \\n\\n,    \\n\\n .< 2021. 11. 19.>\\n \\n\\n27(   )   211  \\n\\n            7  \\n\\n    .\\n\\n1.  1451   (   \\n\\n)\\n\\n\\n\\n                                                            11                                                       \\n\\n \\n\\n2.    \\n\\n  211          \\n\\n    8       .\\n\\n1.  1451   \\n\\n2.    \\n\\n3.     \\n\\n4.  21 6      \\n\\n5.    \\n \\n\\n28(     )  2145 \\n\\n         .\\n\\n1.         \\n\\n2.          \\n\\n3.          \\n\\n4.          \\n\\n5.         \\n\\n6.           \\n\\n7.         \\n \\n\\n29(  )   221      \\n\\n  20   5       \\n\\n 50   . ,         \\n\\n. < 2021. 11. 19.>\\n\\n1.    \\n\\n2.  185      \\n\\n     .\\n\\n  1  2      \\n\\n       14    \\n\\n      .\\n\\n 2         ,    \\n\\n .\\n \\n\\n30( )      \\n\\n,          .\\n \\n\\n31(  )        .\\n\\n1.  134          ,    \\n\\n     \\n\\n\\n\\n                                                            12                                                       \\n\\n \\n\\n2.         \\n\\n3.             \\n\\n  \\n\\n     142 .   \\n\\n ,  151 1 .\\n \\n\\n32(  )        \\n\\n   231  ( \\n\\n)   .\\n\\n1.          \\n\\n   (       \\n\\n          \\n\\n  .  )     \\n\\n2.    10       \\n\\n            \\n\\n\\n\\n3.              \\n\\n  \\n\\n4.              \\n\\n    \\n\\n      .   11   \\n\\n          (8  )  ,  \\n\\n12 4       8\\n\\n 10    .\\n\\n1.       101  ( \\n\\n )    \\n\\n2.           \\n\\n3.            \\n\\n4.          \\n\\n5. ,          \\n\\n6.              \\n\\n  \\n\\n7.     \\n\\n8.      \\n\\n9.         \\n\\n10.           \\n\\n \\n\\n\\n\\n                                                            13                                                       \\n\\n \\n\\n   2 ,   .\\n\\n          \\n\\n.\\n\\n 1 4         \\n\\n   .\\n \\n\\n33( )        \\n\\n  ()  .\\n\\n1.     3211   \\n\\n   \\n\\n2. 3212 4      \\n\\n     \\n\\n3.       \\n\\n4.          \\n \\n\\n34(  )  241   \\n\\n         9 .\\n \\n\\n35( )       \\n\\n .\\n\\n1. \\n\\n2.        1  \\n\\n\\n\\n3.   9( 2    9  \\n\\n   )    \\n\\n       .  ,  \\n\\n50  100    5    \\n\\n .\\n\\n1.   (         \\n\\n .  )\\n\\n2. (161      , \\n\\n        \\n\\n  ) 1\\n\\n3. (201      , \\n\\n        \\n\\n  ) 1\\n\\n4. (     )\\n\\n\\n\\n                                                            14                                                       \\n\\n \\n\\n5.     9     \\n\\n 1  2   691  ( \\n\\n )  6411        \\n\\n          .\\n\\n1. :        , \\n\\n     \\n\\n2. :  ,     \\n \\n\\n36( )     (\\n\\n).       1    .\\n \\n\\n37(  )   243   \\n\\n   ,    \\n\\n,      .\\n\\n        ()  \\n\\n  .\\n\\n , ,   ,    \\n\\n          1  \\n\\n    .\\n\\n           \\n\\n.\\n\\n1.    \\n\\n2. \\n\\n3.     \\n\\n4.   \\n \\n\\n38(    )        \\n\\n       \\n\\n  3    .\\n\\n1.  242         \\n\\n2.          \\n\\n \\n\\n 1          ,\\n\\n     .\\n \\n\\n39(   )    \\n\\n          (),  \\n\\n ,        .\\n\\n\\n\\n                                                            15                                                       \\n\\n \\n\\n \\n\\n            3 \\n \\n\\n40(   )   331    291\\n\\n 3     ( \\n\\n )          \\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 2    10       \\n\\n.\\n\\n  331    311     \\n\\n          \\n\\n2    11      .\\n\\n  331    321       \\n\\n  (  )     \\n\\n      .\\n\\n1.   (  )\\n\\n2.         12     \\n\\n\\n\\n.       2  \\n\\n. \\n\\n  331         \\n\\n.\\n\\n1.  ()\\n\\n2.  \\n\\n3.  \\n\\n 1 3      334 \\n\\n  2145      \\n\\n   .\\n\\n1.      \\n\\n2.       \\n\\n3.      \\n\\n4.  291 3, 311   321     \\n\\n       \\n\\n \\n\\n            4   \\n \\n\\n\\n\\n                                                            16                                                       \\n\\n \\n\\n41(3       )  412 \\n\\n               \\n\\n  . < 2021. 10. 14.>\\n\\n1.     \\n\\n2.  541   \\n\\n3.  412         \\n\\n4.         412  \\n\\n  ,         \\n\\n[ 2021. 10. 14.]\\n \\n\\n42(  )   4211  \\n\\n            \\n\\n  300   .\\n\\n1.  ;    \\n\\n2.   \\n\\n3.     \\n\\n4.    \\n\\n5.  \\n\\n6.    \\n\\n7.    \\n\\n8.   \\n\\n9. 1  \\n\\n10.  \\n\\n11.    \\n\\n12.  \\n\\n13.  \\n\\n  4212        \\n\\n      .       \\n\\n       .< 2021. 11. 19.>\\n\\n1.     \\n\\n2. \\n\\n3. \\n\\n4.  \\n\\n5.           \\n\\n   \\n\\n6.  <2021. 11. 19.>\\n\\n\\n\\n                                                            17                                                       \\n\\n \\n\\n  4213       \\n\\n       .\\n\\n1.                          (\\n\\n  )  \\n\\n.  31    \\n\\n.  3  \\n\\n.  5       \\n\\n1)   (   )\\n\\n2) , (    )\\n\\n3) \\n\\n4)   \\n\\n5)   \\n\\n6) \\n\\n7)  \\n\\n2.  5      \\n\\n3.  ()(    ) 50   \\n\\n \\n\\n4.   \\n\\n5. , ,  2         \\n\\n \\n\\n6.  10  \\n \\n\\n43(  )   441    \\n\\n            \\n\\n   ,        13  \\n\\n              \\n\\n     .\\n\\n1.  \\n\\n2.   \\n\\n3.         . , \\n\\n      13 1  2   \\n\\n.\\n\\n4.  ,         \\n\\n5.        (     \\n\\n)\\n\\n6.      [ ()  ]\\n\\n\\n\\n                                                            18                                                       \\n\\n \\n\\n7.    \\n\\n 1          .\\n\\n1.  \\n\\n2. \\n\\n3.            \\n\\n4. \\n\\n5.   \\n\\n6.       \\n\\n7.   \\n\\n8.           \\n\\n     \\n\\n  441          \\n\\n  .\\n\\n1.       1  (2   \\n\\n.  2 )  \\n\\n2.         1   \\n\\n\\n \\n\\n44( )   441     \\n\\n   .\\n\\n1. \\n\\n2.  \\n\\n3. \\n\\n4. \\n\\n5.          \\n\\n 11 4        \\n\\n.\\n \\n\\n45( )   43     (\\n\\n       \\n\\n13       ) \\n\\n           44\\n\\n1       .  \\n\\n        23 \\n\\n  44      \\n\\n         23  \\n\\n     . < 2020. 9. 8.>\\n\\n\\n\\n                                                            19                                                       \\n\\n \\n\\n 1        \\n\\n 2           \\n\\n  11     132   \\n\\n    28      \\n\\n           \\n\\n.\\n \\n\\n46(   )   471  ( \\n\\n )     14 .\\n\\n   471      \\n\\n         .\\n\\n      ,  \\n\\n     .\\n \\n\\n47(  )  481   \\n\\n   461   14    \\n\\n  15,   16,   17    \\n\\n    .\\n \\n\\n48(    )  484    21\\n\\n45          \\n\\n.\\n\\n1.       \\n\\n2.        \\n\\n3. 47          \\n\\n4.        \\n\\n5.       \\n\\n6.         \\n\\n7.         \\n \\n\\n49(    )  491    \\n\\n         .\\n\\n1.      2  \\n\\n2.  4912  \\n\\n3.    2 ( 1    3 ) \\n\\n\\n\\n4.    ,         \\n\\n   \\n\\n\\n\\n                                                            20                                                       \\n\\n \\n\\n50(  )  4913    \\n\\n        2   \\n\\n.\\n\\n \\n\\n            5    \\n \\n\\n51(  )  591   ,     \\n\\n             \\n\\n.\\n\\n1.  1  , ,      \\n\\n       . ,  \\n\\n         \\n\\n.\\n\\n2.     81  \\n\\n(  )    \\n\\n \\n \\n\\n52(  )  621  (\\n\\n )        \\n\\n     100(   , 1 \\n\\n     50)     \\n\\n   20   .\\n \\n\\n53(  )   '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'      \\n\\n(  )  , , \\n\\n           \\n\\n 261     (     \\n\\n)      .      \\n\\n           \\n\\n .\\n\\n  3013          \\n\\n   4      .\\n\\n1.  321        403  (\\n\\n )  \\n\\n2.  321          \\n\\n3.  321          \\n\\n\\n\\n\\n\\n                                                            11                                                       \\n\\n \\n\\n4.  9812    \\n\\n5.        \\n\\n   302         \\n\\n              .\\n\\n1.  22        \\n\\n 6        1   : \\n\\n4     100 50 \\n\\n2.  5   6         \\n\\n  :  4    100 50 \\n\\n.    1        \\n\\n\\n\\n.         1     \\n\\n  \\n\\n3.             \\n\\n    :       \\n\\n     \\n\\n4.            \\n \\n\\n28(     )   311   \\n\\n    (   \\n\\n)   4 ,   5 .\\n\\n      (  \\n\\n )      5   \\n\\n  ,   11     .\\n\\n 1  2          \\n\\n  .\\n \\n\\n29(   )   321     \\n\\n          (  .\\n\\n )   3(   1 )  \\n\\n      ,     2   \\n\\n  3       \\n\\n.\\n\\n1.  151  \\n\\n2.  171  (    30\\n\\n3       )\\n\\n\\n\\n                                                            12                                                       \\n\\n \\n\\n3.  181  \\n\\n4.  191  \\n\\n5.  211       \\n\\n    \\n\\n6.  741     \\n\\n7.  961      \\n\\n8.  1001      \\n\\n9.  1201      \\n\\n 1    (  )   4\\n\\n,   5 .\\n\\n    , ,    , \\n\\n ,        .\\n \\n\\n30( )   321          \\n\\n       .\\n\\n1.  191  \\n\\n2.   4 6  \\n\\n3.   4 7  \\n\\n   4 8      ,    \\n\\n 3034  5      , \\n\\n   6 2  3       \\n\\n292          \\n\\n        .\\n\\n 291          \\n\\n        .\\n \\n\\n31(  )   401  3  \\n\\n             \\n\\n    .\\n\\n1.  401    :  9 \\n\\n       \\n\\n.   401        \\n\\n2     \\n\\n.   10        ( \\n\\n), ,     \\n\\n.   10           \\n\\n\\n\\n\\n\\n                                                            13                                                       \\n\\n \\n\\n.  1 \\n\\n2.  403    :  10 \\n\\n       \\n\\n.  403       \\n\\n.   12       ( \\n\\n), ,     \\n\\n.   12           \\n\\n\\n\\n.  1 \\n\\n 1      361 \\n\\n         . ,  1\\n\\n 3          .\\n\\n1. \\n\\n2. ( )\\n\\n3. ( )\\n\\n  1     401  3  \\n\\n       20   11  \\n\\n 12       \\n\\n .\\n\\n 3         \\n\\n    .\\n\\n  331       \\n\\n9   10      \\n\\n   .     \\n\\n3 .\\n\\n          3  \\n\\n5     .\\n \\n\\n32(  )    332  \\n\\n     .\\n\\n1.     \\n\\n2.    \\n\\n3.    \\n\\n 1           17\\n\\n2 8  .     \\n\\n  .\\n\\n\\n\\n                                                            14                                                       \\n\\n \\n\\n33(   )   \\n\\n    13    \\n\\n      .\\n\\n1.  402    \\n\\n2.   11       ( \\n\\n), ,     \\n\\n3.   11         \\n\\n\\n\\n 1      361  \\n\\n        . , 1  3 \\n\\n          .\\n\\n1. \\n\\n2. ( )\\n\\n3. ( )\\n\\n  1      15   402\\n\\n           \\n\\n.\\n\\n  3     7     \\n\\n ,          14 \\n\\n     .\\n\\n       13 \\n\\n       (\\n\\n    )    .\\n\\n 5     3  4 . , \\n\\n            \\n\\n ,   (     \\n\\n)  .\\n \\n\\n34(    )    334  \\n\\n             \\n\\n        .\\n\\n    334        \\n\\n  .\\n \\n\\n35(  )      15  \\n\\n    .\\n\\n\\n\\n                                                            15                                                       \\n\\n \\n\\n     15       \\n\\n  .\\n\\n           \\n\\n          .\\n\\n       12 31  \\n\\n   (   ) \\n\\n  .\\n \\n\\n36( )     331    29'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                  20                                                       \\n\\n \\n\\n1. \\n\\n.       \\n\\n.   \\n\\n.      \\n\\n.        \\n\\n.   \\n\\n.    \\n\\n.      \\n\\n2.              (\\n\\n              \\n\\n       ,    \\n\\n     )\\n\\n. (Check List)\\n\\n.  (Dow and Mond Indices)\\n\\n.   (HEA)\\n\\n.    (What-if)\\n\\n.   (HAZOP)\\n\\n.  (FMECA)\\n\\n.   (FTA)\\n\\n.   (ETA)\\n\\n.  (CCA)\\n\\n.        \\n\\n3. \\n\\n. \\n\\n.   ,   \\n\\n. \\n\\n.  \\n\\n.   \\n\\n.   \\n\\n.  \\n\\n.   \\n\\n.     \\n\\n4. \\n\\n.    \\n\\n.      \\n\\n\\n\\n                                                            21                                                       \\n\\n \\n\\n.         \\n\\n.   \\n\\n. \\n\\n.     \\n\\n   ,   ,     \\n\\n   .\\n \\n\\n51(  )   451    \\n\\n      (   \\n\\n      13   \\n\\n      ) 30   2 \\n\\n   .\\n \\n\\n52(  )   51    \\n\\n   30   1  ,   \\n\\n   .\\n\\n  1       \\n\\n           \\n\\n  .\\n \\n\\n53(  )        \\n\\n462         . ,   \\n\\n,          \\n\\n  ,            \\n\\n    503       \\n\\n      .\\n\\n1.             \\n\\n  1\\n\\n2.            3 \\n\\n3.             1\\n\\n\\n\\n4.             \\n\\n 1 . ,  47      \\n\\n        .\\n\\n      1  501 4\\n\\n     ,   15    \\n\\n     .\\n\\n\\n\\n                                                            22                                                       \\n\\n \\n\\n 1  2         \\n\\n.\\n \\n\\n54(   )   464   \\n\\n 2   (     \\n\\n       )  1   2  \\n\\n   (  )  .\\n\\n  1    4   . \\n\\n,        1  2    .\\n\\n1.      \\n\\n2.  155          50\\n\\n13        \\n\\n       \\n\\n  501       \\n\\n.\\n\\n         \\n\\n.\\n \\n\\n55( )  471     25\\n\\n.\\n \\n\\n56( )  472      15\\n\\n    .\\n \\n\\n57(  )  472    \\n\\n   14          \\n\\n      30      \\n\\n   (   ) .\\n \\n\\n58(  )   482    \\n\\n    .\\n\\n1.        \\n\\n2.       \\n\\n3.    \\n\\n  482          \\n\\n172 8  .     \\n\\n  .\\n \\n\\n\\n\\n                                                            23                                                       \\n\\n \\n\\n59(  )      \\n\\n483   6       \\n\\n  (   ) .\\n\\n1. \\n\\n2.   15,  16   17       \\n\\n   ( ),     \\n\\n3.            \\n\\n\\n\\n4.  1 \\n\\n 1      361 \\n\\n        ,\\n\\n          .\\n\\n    ,   ,    \\n\\n 163 6  .     \\n\\n ,   \\n\\n .\\n \\n\\n60(  )  491   \\n\\n   26 .\\n \\n\\n61(  )   501   \\n\\n    491      \\n\\n 60       ( \\n\\n ) .\\n\\n 1   ,  ,  ,  \\n\\n        .\\n \\n\\n62(  )    61  \\n\\n    15      \\n\\n .\\n\\n  502     612\\n\\n       .    \\n\\n         .\\n \\n\\n63(     )  531    \\n\\n           \\n\\n.\\n\\n\\n\\n                                                            24                                                       \\n\\n \\n\\n1.       \\n\\n   \\n\\n2.  87   \\n\\n3.  92   \\n\\n4.  95   \\n\\n5.  992   \\n\\n6.  1171   \\n\\n7.  1181     \\n \\n\\n64( )    531    \\n\\n  27      ( \\n\\n )    .\\n\\n  1        \\n\\n .\\n\\n 1          \\n\\n          \\n\\n   .\\n\\n  1         \\n\\n       .\\n\\n    535       \\n\\n  .\\n \\n\\n65( )    533      \\n\\n    27     \\n\\n (  )    .\\n\\n     6425 .   \\n\\n ,   ,\\n\\n  .\\n \\n\\n66(  )  531      \\n\\n     532       \\n\\n     .\\n \\n\\n67(   )         \\n\\n542           \\n\\n         .\\n\\n1.     \\n\\n\\n\\n                                                            25                                                       \\n\\n \\n\\n2.   \\n\\n3.    \\n \\n\\n68()  551      28\\n\\n    .\\n \\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# examples\n",
    "strings, relatednesses = strings_ranked_by_relatedness(\"    ?\", df, top_n=5)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121fd40",
   "metadata": {},
   "source": [
    "####  ####\n",
    "   ,      GPT   \n",
    "   :\n",
    "-    \n",
    "-    \n",
    "- GPT    Stuffs \n",
    "-  GPT  \n",
    "- GPT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f93c2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f0b9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = '     .      \"  \"  \"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\n :\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a759140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "GPT_MODEL = 'gpt-3.5-turbo'\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"       .\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a9134",
   "metadata": {},
   "source": [
    "####   ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0162e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     .      \"  \"  \"\n",
      "\n",
      "Question:      ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    17  .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"     ?\", model=\"gpt-3.5-turbo\", print_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9606b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     17  .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"       ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a83824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390030b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a94d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70361053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775dc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bf7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e702910",
   "metadata": {},
   "source": [
    "#### Dataframe to dict ####\n",
    "- to_dict method convert dataframe object to dict format\n",
    "- orient: define the format of dict output. \n",
    "- records is one of format.  records return [{column: value, column:value}, {column:value column, value}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "d7a3707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd0a8b83aab40c1ae6ee91fcccd0765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = len(df)   # how many records in df will be inserted at once \n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "\n",
    "chunks = df.to_dict(orient='records')\n",
    "\n",
    "# Upsert embeddings into Pincecoine in batches of 5\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    embeddings = [x['embeddings'] for x in meta_batch]\n",
    "    data = [{\n",
    "        'texts': x['texts']     \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeddings, data))\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "94b9c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='indsec-idx', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='p1.x1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.describe_index('indsec-idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f1d9a665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 150}},\n",
       " 'total_vector_count': 150}"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1728ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d517c1e",
   "metadata": {},
   "source": [
    "#### Making Queries ####\n",
    "- To search, need to create a query vector xq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "e9082dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "query = \"    ? \"    #  29\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "3d2f8864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '119',\n",
       "              'metadata': {'texts': ', ,  -) '\n",
       "                                    '044-202-8942, 8939, 8940  '\n",
       "                                    '(-MSDS, PSM) 044-202-8971, 8967\\n'\n",
       "                                    '\\n'\n",
       "                                    '         \\n'\n",
       "                                    '\\n'\n",
       "                                    '3( )     . ,  '\n",
       "                                    ',  ,    (   '\n",
       "                                    ' .  )       '\n",
       "                                    '        \\n'\n",
       "                                    '\\n'\n",
       "                                    '9.            '\n",
       "                                    '1       '\n",
       "                                    '  (  '\n",
       "                                    '),            '\n",
       "                                    '.\\n'\n",
       "                                    '\\n'\n",
       "                                    '          '\n",
       "                                    '.\\n'\n",
       "                                    '\\n'\n",
       "                                    '  78       . '\n",
       "                                    '    6  )      '\n",
       "                                    '(77    78   '\n",
       "                                    '    .     6  '\n",
       "                                    ')         '\n",
       "                                    '. <\\n'\n",
       "                                    '\\n'\n",
       "                                    '          '\n",
       "                                    '            , '\n",
       "                                    '       '\n",
       "                                    '     1.     '\n",
       "                                    '    2.     3. '\n",
       "                                    '  \\n'\n",
       "                                    '\\n'\n",
       "                                    '        '\n",
       "                                    ', ,        '\n",
       "                                    '  .       '\n",
       "                                    '           '\n",
       "                                    '            . '\n",
       "                                    '          '\n",
       "                                    '        . 1. '\n",
       "                                    ' 8   111    '\n",
       "                                    ' 2.  15      '\n",
       "                                    '    3.       '\n",
       "                                    '     \\n'\n",
       "                                    '\\n'\n",
       "                                    '    . < 2020. 5. 26.> 1. '\n",
       "                                    '     ,    2. '\n",
       "                                    '     3.    '\n",
       "                                    '    4.     '\n",
       "                                    '  \\n'\n",
       "                                    '\\n'\n",
       "                                    '1. 11          2. '\n",
       "                                    '           '\n",
       "                                    '3.         '\n",
       "                                    ' \\n'\n",
       "                                    '\\n'\n",
       "                                    '2   1 \\n'\n",
       "                                    '\\n'\n",
       "                                    '16()         '\n",
       "                                    '      (  '\n",
       "                                    ')           '\n",
       "                                    '  .       '\n",
       "                                    '6412      3   '\n",
       "                                    '   .\\n'\n",
       "                                    '\\n'\n",
       "                                    '       '\n",
       "                                    '   (  )  '\n",
       "                                    '.     '},\n",
       "              'score': 0.848154485,\n",
       "              'values': []},\n",
       "             {'id': '112',\n",
       "              'metadata': {'texts': '-, ,  -) '\n",
       "                                    '044-202-8942, 8939, 8940  '\n",
       "                                    '(-MSDS, PSM) 044-202-8971, 8967\\n'\n",
       "                                    '\\n'\n",
       "                                    '         \\n'\n",
       "                                    '\\n'\n",
       "                                    '3( )     . ,  '\n",
       "                                    ',  ,    (   '\n",
       "                                    ' .  )       '\n",
       "                                    '        \\n'\n",
       "                                    '\\n'\n",
       "                                    '9.            '\n",
       "                                    '1       '\n",
       "                                    '  (  '\n",
       "                                    '),            '\n",
       "                                    '.\\n'\n",
       "                                    '\\n'\n",
       "                                    '          '\n",
       "                                    '.\\n'\n",
       "                                    '\\n'\n",
       "                                    '  78       . '\n",
       "                                    '    6  )      '\n",
       "                                    '(77    78   '\n",
       "                                    '    .     6  '\n",
       "                                    ')         '\n",
       "                                    '. <\\n'\n",
       "                                    '\\n'\n",
       "                                    '          '\n",
       "                                    '            , '\n",
       "                                    '       '\n",
       "                                    '     1.     '\n",
       "                                    '    2.     3. '\n",
       "                                    '  \\n'\n",
       "                                    '\\n'\n",
       "                                    '        '\n",
       "                                    ', ,        '\n",
       "                                    '  .       '\n",
       "                                    '           '\n",
       "                                    '            . '\n",
       "                                    '          '\n",
       "                                    '        . 1. '\n",
       "                                    ' 8   111    '\n",
       "                                    ' 2.  15      '\n",
       "                                    '    3.       '\n",
       "                                    '     \\n'\n",
       "                                    '\\n'\n",
       "                                    '    . < 2020. 5. 26.> 1. '\n",
       "                                    '     ,    2. '\n",
       "                                    '     3.    '\n",
       "                                    '    4.     '\n",
       "                                    '  \\n'\n",
       "                                    '\\n'\n",
       "                                    '1. 11          2. '\n",
       "                                    '           '\n",
       "                                    '3.         '\n",
       "                                    ' \\n'\n",
       "                                    '\\n'\n",
       "                                    '2   1 \\n'\n",
       "                                    '\\n'\n",
       "                                    '16()         '\n",
       "                                    '      (  '\n",
       "                                    ')           '\n",
       "                                    '  .       '\n",
       "                                    '6412      3   '\n",
       "                                    '   .\\n'\n",
       "                                    '\\n'\n",
       "                                    '       '\n",
       "                                    '   (  )  '\n",
       "                                    '.   '},\n",
       "              'score': 0.848094225,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "f8f63815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '119',\n",
       "  'metadata': {'texts': ', ,  -) 044-202-8942, 8939, 8940 '\n",
       "                        ' (-MSDS, PSM) 044-202-8971, 8967\\n'\n",
       "                        '\\n'\n",
       "                        '         \\n'\n",
       "                        '\\n'\n",
       "                        '3( )     . ,  ,  , '\n",
       "                        '   (    .  )   '\n",
       "                        '            \\n'\n",
       "                        '\\n'\n",
       "                        '9.            1    '\n",
       "                        '     (  '\n",
       "                        '),            .\\n'\n",
       "                        '\\n'\n",
       "                        '          .\\n'\n",
       "                        '\\n'\n",
       "                        '  78       .     6 '\n",
       "                        ' )      (77    '\n",
       "                        '78       .     6  '\n",
       "                        ')         . <\\n'\n",
       "                        '\\n'\n",
       "                        '                '\n",
       "                        '      ,     '\n",
       "                        '        1.     '\n",
       "                        '    2.     3.   '\n",
       "                        '\\n'\n",
       "                        '\\n'\n",
       "                        '        , ,   '\n",
       "                        '       .     '\n",
       "                        '              '\n",
       "                        '           .     '\n",
       "                        '             '\n",
       "                        ' . 1.  8   111    '\n",
       "                        ' 2.  15          3. '\n",
       "                        '           \\n'\n",
       "                        '\\n'\n",
       "                        '    . < 2020. 5. 26.> 1.     '\n",
       "                        ' ,    2.      3.  '\n",
       "                        '      4.      '\n",
       "                        ' \\n'\n",
       "                        '\\n'\n",
       "                        '1. 11          2.     '\n",
       "                        '       3.       '\n",
       "                        '   \\n'\n",
       "                        '\\n'\n",
       "                        '2   1 \\n'\n",
       "                        '\\n'\n",
       "                        '16()            '\n",
       "                        '   (  )        '\n",
       "                        '     .      '\n",
       "                        ' 6412      3     '\n",
       "                        ' .\\n'\n",
       "                        '\\n'\n",
       "                        '         '\n",
       "                        ' (  )  .     '},\n",
       "  'score': 0.848154485,\n",
       "  'values': []},\n",
       " {'id': '112',\n",
       "  'metadata': {'texts': '-, ,  -) 044-202-8942, '\n",
       "                        '8939, 8940  (-MSDS, PSM) 044-202-8971, '\n",
       "                        '8967\\n'\n",
       "                        '\\n'\n",
       "                        '         \\n'\n",
       "                        '\\n'\n",
       "                        '3( )     . ,  ,  , '\n",
       "                        '   (    .  )   '\n",
       "                        '            \\n'\n",
       "                        '\\n'\n",
       "                        '9.            1    '\n",
       "                        '     (  '\n",
       "                        '),            .\\n'\n",
       "                        '\\n'\n",
       "                        '          .\\n'\n",
       "                        '\\n'\n",
       "                        '  78       .     6 '\n",
       "                        ' )      (77    '\n",
       "                        '78       .     6  '\n",
       "                        ')         . <\\n'\n",
       "                        '\\n'\n",
       "                        '                '\n",
       "                        '      ,     '\n",
       "                        '        1.     '\n",
       "                        '    2.     3.   '\n",
       "                        '\\n'\n",
       "                        '\\n'\n",
       "                        '        , ,   '\n",
       "                        '       .     '\n",
       "                        '              '\n",
       "                        '           .     '\n",
       "                        '             '\n",
       "                        ' . 1.  8   111    '\n",
       "                        ' 2.  15          3. '\n",
       "                        '           \\n'\n",
       "                        '\\n'\n",
       "                        '    . < 2020. 5. 26.> 1.     '\n",
       "                        ' ,    2.      3.  '\n",
       "                        '      4.      '\n",
       "                        ' \\n'\n",
       "                        '\\n'\n",
       "                        '1. 11          2.     '\n",
       "                        '       3.       '\n",
       "                        '   \\n'\n",
       "                        '\\n'\n",
       "                        '2   1 \\n'\n",
       "                        '\\n'\n",
       "                        '16()            '\n",
       "                        '   (  )        '\n",
       "                        '     .      '\n",
       "                        ' 6412      3     '\n",
       "                        ' .\\n'\n",
       "                        '\\n'\n",
       "                        '         '\n",
       "                        ' (  )  .   '},\n",
       "  'score': 0.848094225,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "726d8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 3000\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['texts'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e4697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "13745b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's make it simpler to get answers\n",
    "def complete(prompt):\n",
    "    # query text-embedding-ada-002\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "77cfbbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.\\n\\nContext:\\n, ,  -) 044-202-8942, 8939, 8940  (-MSDS, PSM) 044-202-8971, 8967\\n\\n         \\n\\n3( )     . ,  ,  ,    (    .  )               \\n\\n9.            1         (  ),            .\\n\\n          .\\n\\n  78       .     6  )      (77    78       .     6  )         . <\\n\\n                      ,             1.         2.     3.   \\n\\n        , ,          .                              .                   . 1.  8   111     2.  15          3.            \\n\\n    . < 2020. 5. 26.> 1.      ,    2.      3.        4.       \\n\\n1. 11          2.            3.          \\n\\n2   1 \\n\\n16()               (  )             .       6412      3      .\\n\\n          (  )  .     \\n\\nQuestion:     ? \\nAnswer:'"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "6bbb1c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4323 tokens (4123 in your prompt; 200 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[527], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# then we complete the context-infused query\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_with_contexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[525], line 4\u001b[0m, in \u001b[0;36mcomplete\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomplete\u001b[39m(prompt):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# query text-embedding-ada-002\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4323 tokens (4123 in your prompt; 200 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "# then we complete the context-infused query\n",
    "complete(query_with_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c3e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba0f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd4ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313acef8",
   "metadata": {},
   "source": [
    "#### To make expanded query sampler, we pack function named retrieve ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf9122",
   "metadata": {},
   "source": [
    "limit = 3750\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6a594",
   "metadata": {},
   "source": [
    "#### Using retrieve we return the expanded query: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769c6b4",
   "metadata": {},
   "source": [
    "#### Pass our expanded query to the LLM: ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c637ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we complete the context-infused query\n",
    "complete(query_with_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a48bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebb2bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36acf762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks_embedding_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e117874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_embedding_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f7030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
